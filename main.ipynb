{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIBRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                    #to load dataset\n",
    "import matplotlib.pyplot as plt       #to plot datase3t graphically\n",
    "import keras                          #python predefined library to retreive dataset\n",
    "from keras.datasets import mnist      #loading dataset\n",
    "from keras.models import Sequential   #Modelling the dataset\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout       #to preprocess dataset to feed on the ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mnist.npz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Loads the MNIST dataset.\n",
      "\n",
      "This is a dataset of 60,000 28x28 grayscale images of the 10 digits,\n",
      "along with a test set of 10,000 images.\n",
      "More info can be found at the\n",
      "[MNIST homepage](http://yann.lecun.com/exdb/mnist/).\n",
      "\n",
      "Args:\n",
      "  path: path where to cache the dataset locally\n",
      "    (relative to `~/.keras/datasets`).\n",
      "\n",
      "Returns:\n",
      "  Tuple of NumPy arrays: `(x_train, y_train), (x_test, y_test)`.\n",
      "\n",
      "**x_train**: uint8 NumPy array of grayscale image data with shapes\n",
      "  `(60000, 28, 28)`, containing the training data. Pixel values range\n",
      "  from 0 to 255.\n",
      "\n",
      "**y_train**: uint8 NumPy array of digit labels (integers in range 0-9)\n",
      "  with shape `(60000,)` for the training data.\n",
      "\n",
      "**x_test**: uint8 NumPy array of grayscale image data with shapes\n",
      "  (10000, 28, 28), containing the test data. Pixel values range\n",
      "  from 0 to 255.\n",
      "\n",
      "**y_test**: uint8 NumPy array of digit labels (integers in range 0-9)\n",
      "  with shape `(10000,)` for the test data.\n",
      "\n",
      "Example:\n",
      "\n",
      "```python\n",
      "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
      "assert x_train.shape == (60000, 28, 28)\n",
      "assert x_test.shape == (10000, 28, 28)\n",
      "assert y_train.shape == (60000,)\n",
      "assert y_test.shape == (10000,)\n",
      "```\n",
      "\n",
      "License:\n",
      "  Yann LeCun and Corinna Cortes hold the copyright of MNIST dataset,\n",
      "  which is a derivative work from original NIST datasets.\n",
      "  MNIST dataset is made available under the terms of the\n",
      "  [Creative Commons Attribution-Share Alike 3.0 license.](\n",
      "  https://creativecommons.org/licenses/by-sa/3.0/)\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\keras\\datasets\\mnist.py\n",
      "\u001b[1;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    " mnist.load_data?\n",
    " (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train.shape , y_train.shape , X_test.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train.shape , y_train.shape , X_test.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCRESSING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)/255            #normalizing the data\n",
    "X_test = X_test.astype(np.float32)/255\n",
    "\n",
    "X_train = np.expand_dims(X_train, -1)               #reshaping dataset to feed model\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "\n",
    "\n",
    "X_train.shape\n",
    "#converting classes into one hot vector\n",
    "\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), input_shape = (28,28,1), activation = 'relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_16 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 13, 13, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 5, 5, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                16010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam', loss = keras.losses.categorical_crossentropy, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "#earlystopping\n",
    "es = EarlyStopping(monitor='val_acc', min_delta = 0.01, patience=4, verbose=1)\n",
    "\n",
    "#Modelcheckpoint\n",
    "mc = ModelCheckpoint(\".//bestmodel.h5\", monitor=\"val_acc\", verbose = 1, save_best_only= True)\n",
    "\n",
    "cb = [es,mc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1310/1313 [============================>.] - ETA: 0s - loss: 0.2227 - accuracy: 0.9323WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 55s 41ms/step - loss: 0.2224 - accuracy: 0.9324 - val_loss: 0.0847 - val_accuracy: 0.9743\n",
      "Epoch 2/10\n",
      "1311/1313 [============================>.] - ETA: 0s - loss: 0.0754 - accuracy: 0.9771WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 27s 21ms/step - loss: 0.0754 - accuracy: 0.9771 - val_loss: 0.0614 - val_accuracy: 0.9816\n",
      "Epoch 3/10\n",
      "1311/1313 [============================>.] - ETA: 0s - loss: 0.0573 - accuracy: 0.9821WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 26s 19ms/step - loss: 0.0573 - accuracy: 0.9821 - val_loss: 0.0602 - val_accuracy: 0.9824\n",
      "Epoch 4/10\n",
      "1310/1313 [============================>.] - ETA: 0s - loss: 0.0448 - accuracy: 0.9858WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 26s 20ms/step - loss: 0.0447 - accuracy: 0.9858 - val_loss: 0.0483 - val_accuracy: 0.9855\n",
      "Epoch 5/10\n",
      "1313/1313 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9877WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 27s 21ms/step - loss: 0.0369 - accuracy: 0.9877 - val_loss: 0.0470 - val_accuracy: 0.9858\n",
      "Epoch 6/10\n",
      "1312/1313 [============================>.] - ETA: 0s - loss: 0.0317 - accuracy: 0.9901WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 43s 33ms/step - loss: 0.0317 - accuracy: 0.9901 - val_loss: 0.0454 - val_accuracy: 0.9868\n",
      "Epoch 7/10\n",
      " 756/1313 [================>.............] - ETA: 24s - loss: 0.0272 - accuracy: 0.9911"
     ]
    }
   ],
   "source": [
    "his = model.fit(X_train, y_train, epochs = 10, validation_split = 0.3, callbacks = cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_64208/2649484481.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Lenovo\\AppData\\Local\\Temp/ipykernel_64208/2649484481.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    model_S = keras.models.load_model( //bestmodel.h5)\u001b[0m\n\u001b[1;37m                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model_S = keras.models.load_model( \"C:\\Users\\Lenovo\\OneDrive\\Desktop\\Handwritten\\main.ipynb//bestmodel.h5\")\n",
    "score = model_S.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"the model accuracy is {score[1]} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c3d4d9970fc5c09c50d9318a9c7fbf4d0159e4b28833276f5678ee22bded273"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
